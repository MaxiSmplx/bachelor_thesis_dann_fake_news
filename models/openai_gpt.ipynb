{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from random import randint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = load_dataset(\"csv\", data_files=\"../datasets/FakeNewsDetection/fakenewsdetection_real.csv\")[\"train\"]\n",
    "real_data = real_data.add_column(\"label\", [0] * len(real_data))\n",
    "\n",
    "fake_data = load_dataset(\"csv\", data_files=\"../datasets/FakeNewsDetection/fakenewsdetection_fake.csv\")[\"train\"]\n",
    "fake_data = fake_data.add_column(\"label\", [1] * len(fake_data))\n",
    "\n",
    "data = concatenate_datasets([real_data, fake_data])\n",
    "\n",
    "NO_SAMPLES = 100\n",
    "data = data.shuffle(seed=randint(1, 100)).select(range(NO_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1db64896c44407eb7eec6d0e0194a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def combine_title_and_text(data):\n",
    "    data[\"full_text\"] = data[\"title\"] + \" \" + data[\"text\"]\n",
    "    return data\n",
    "\n",
    "data = data.map(combine_title_and_text)\n",
    "data = data.remove_columns([\"title\", \"text\", \"subject\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 100\n",
      "1 / 100\n",
      "2 / 100\n",
      "3 / 100\n",
      "4 / 100\n",
      "5 / 100\n",
      "6 / 100\n",
      "7 / 100\n",
      "8 / 100\n",
      "9 / 100\n",
      "10 / 100\n",
      "11 / 100\n",
      "12 / 100\n",
      "13 / 100\n",
      "14 / 100\n",
      "15 / 100\n",
      "16 / 100\n",
      "17 / 100\n",
      "18 / 100\n",
      "19 / 100\n",
      "20 / 100\n",
      "21 / 100\n",
      "22 / 100\n",
      "23 / 100\n",
      "24 / 100\n",
      "25 / 100\n",
      "26 / 100\n",
      "27 / 100\n",
      "28 / 100\n",
      "29 / 100\n",
      "30 / 100\n",
      "31 / 100\n",
      "32 / 100\n",
      "33 / 100\n",
      "34 / 100\n",
      "35 / 100\n",
      "36 / 100\n",
      "37 / 100\n",
      "38 / 100\n",
      "39 / 100\n",
      "40 / 100\n",
      "41 / 100\n",
      "42 / 100\n",
      "43 / 100\n",
      "44 / 100\n",
      "45 / 100\n",
      "46 / 100\n",
      "47 / 100\n",
      "48 / 100\n",
      "49 / 100\n",
      "50 / 100\n",
      "51 / 100\n",
      "52 / 100\n",
      "53 / 100\n",
      "54 / 100\n",
      "55 / 100\n",
      "56 / 100\n",
      "57 / 100\n",
      "58 / 100\n",
      "59 / 100\n",
      "60 / 100\n",
      "61 / 100\n",
      "62 / 100\n",
      "63 / 100\n",
      "64 / 100\n",
      "65 / 100\n",
      "66 / 100\n",
      "67 / 100\n",
      "68 / 100\n",
      "69 / 100\n",
      "70 / 100\n",
      "71 / 100\n",
      "72 / 100\n",
      "73 / 100\n",
      "74 / 100\n",
      "75 / 100\n",
      "76 / 100\n",
      "77 / 100\n",
      "78 / 100\n",
      "79 / 100\n",
      "80 / 100\n",
      "81 / 100\n",
      "82 / 100\n",
      "83 / 100\n",
      "84 / 100\n",
      "85 / 100\n",
      "86 / 100\n",
      "87 / 100\n",
      "88 / 100\n",
      "89 / 100\n",
      "90 / 100\n",
      "91 / 100\n",
      "92 / 100\n",
      "93 / 100\n",
      "94 / 100\n",
      "95 / 100\n",
      "96 / 100\n",
      "97 / 100\n",
      "98 / 100\n",
      "99 / 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompts = [\n",
    "    {\n",
    "        \"text\": sample[\"full_text\"],\n",
    "        \"label_orig\": \"real\" if sample[\"label\"] == 0 else \"fake\"\n",
    "    }\n",
    "    for sample in data\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_SECRET_KEY\"))\n",
    "\n",
    "responses = []\n",
    "def detect_fake_news(prompts):\n",
    "    for n, prompt in enumerate(prompts):\n",
    "        print(f\"{n} / {NO_SAMPLES}\")\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a fake news detector. Respond with only 'real' or 'fake'.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt[\"text\"],\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        label_pred = response.output_text.lower()\n",
    "        responses.append(\n",
    "            {\"prompt\": prompt[\"text\"], \n",
    "             \"label_original\": prompt[\"label_orig\"], \n",
    "             \"label_predicted\": label_pred\n",
    "             }\n",
    "        )\n",
    "    return responses\n",
    "\n",
    "results = detect_fake_news(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 100 - updated length: 100 - removed 0 item(s)\n"
     ]
    }
   ],
   "source": [
    "original_length = len(responses)\n",
    "\n",
    "responses = [\n",
    "    response for response in responses\n",
    "    if response[\"label_predicted\"] in (\"real\", \"fake\")\n",
    "]\n",
    "\n",
    "print(f\"Original length: {original_length} - updated length: {len(responses)} - removed {original_length - len(responses)} item(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 / 100 - Accuracy: 73.00%\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = sum(\n",
    "    1 for response in responses if response[\"label_original\"] == response[\"label_predicted\"]\n",
    ")\n",
    "\n",
    "print(f\"{correctly_predicted} / {NO_SAMPLES} - Accuracy: {(correctly_predicted / NO_SAMPLES) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
