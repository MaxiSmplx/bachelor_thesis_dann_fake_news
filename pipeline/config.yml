# Root directory for all raw datasets
datasets_root: "../datasets"

# Flags for text preprocessing steps
preprocessing:
  lowercase: true
  remove_punctuation: true
  remove_urls: true
  remove_digits: true
  strip_html: true
  remove_special_chars: true
  normalize_whitespace: true

# Domain tagging settings
domain_tagging:
  save_embeddings: true
  use_saved_embeddings: true
  n_domains: 13
  plot: true

# Configuration of data augmentation techniques 
# n_samples: fraction (percent) of the entire DataFrame to augment per step
# only_augment_small_domains: Only datapoints assigned to domain with lowest datavolume will be augmented
augmentation:
  synonym_replacement:
    enabled: false
    n_samples: 0.01
  style_transfer:
    enabled: false
    n_samples: 0.01
  paraphrasing:
    enabled: false
    n_samples: 0.01
  only_augment_small_domains: true
  
# Selection of augmentation method sources
augmentation_methods:
  local_database: false
  llm: true

# Settings for text tokenization
tokenization:
  tokenizer_model: "sentence-transformers/all-MiniLM-L6-v2"
  sequence_max_length: 256

# Settings fo balanced output (lower data volume)
balance_data: 
  balance: true
  balance_tolerance: 0.5

# Dataset is split into Train/Validation and Test, this specifies the testsize in %
test_size: 0.15

# Directory for saving processed data
output: "output" 