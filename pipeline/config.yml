# Root directory for all raw datasets
datasets_root: "../datasets"

# Flags for text preprocessing steps
preprocessing:
  lowercase: true
  remove_punctuation: true
  remove_urls: true
  remove_digits: true
  strip_html: true
  remove_special_chars: true
  normalize_whitespace: true

# Domain tagging settings
domain_tagging:
  save_embeddings: false
  use_saved_embeddings: true
  n_domains: 13
  plot: true

augmentation:
  # Enable or disable specific augmentation techniques
  style_transfer:
    enabled: false
  paraphrasing:
    enabled: false

  # Total number of augmentation requests to send to the OpenAI API per augmentation technique
  # Note: Average cost per 1000 requests is ~$0.18 (based on GPT-4.1 Nano pricing)
  augmentation_budget: 2000

  # Strategy for distributing augmentation across domains
  methods:
    # Augments every domain with an equal number of samples
    equalized: true

    # Prioritizes balancing domains with the fewest samples first
    demand_based: false



# Settings for text tokenization
tokenization:
  tokenizer_model: "sentence-transformers/all-MiniLM-L6-v2"
  sequence_max_length: 256


balance_data:
  # Whether to enable data balancing (reduces overall data volume)
  balance: false

  # Tolerance level for class imbalance when balancing is enabled
  # For example, 0.5 allows up to 50% deviation from perfect balance
  balance_tolerance: 0.5


test_set:
  # Whether to use a cross-domain testing setup
  test_cross_domains: true

  # If cross-domain testing is enabled:
  #   - If true, select n held-out domains (n_domains) randomly
  #   - If false, use the n domains (n_domains) with the fewest samples
  random_domains: false

  # Number of domains to hold out for testing (used only if test_cross_domains is true)
  n_domains: 1

  use_manual_domains: true
  manual_domains: ["Government Policy & Public Affairs"]

  # Proportion of the dataset to use as test set
  # Only applicable if test_cross_domains is false
  test_size: 0.1


# Directory for saving processed data
output: "output" 